//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-26218862
// Cuda compilation tools, release 10.1, V10.1.168
// Based on LLVM 3.4svn
//

.version 6.4
.target sm_30
.address_size 64

	// .globl	compute

.visible .entry compute(
	.param .u64 compute_param_0,
	.param .u64 compute_param_1,
	.param .u64 compute_param_2,
	.param .u64 compute_param_3,
	.param .u64 compute_param_4,
	.param .u32 compute_param_5,
	.param .align 16 .b8 compute_param_6[16],
	.param .align 16 .b8 compute_param_7[32],
	.param .align 16 .b8 compute_param_8[16],
	.param .u32 compute_param_9,
	.param .f64 compute_param_10
)
{
	.reg .pred 	%p<17>;
	.reg .b32 	%r<48>;
	.reg .f64 	%fd<65>;
	.reg .b64 	%rd<19>;


	ld.param.u64 	%rd1, [compute_param_0];
	ld.param.u64 	%rd2, [compute_param_1];
	ld.param.u64 	%rd3, [compute_param_2];
	ld.param.u64 	%rd4, [compute_param_3];
	ld.param.u64 	%rd5, [compute_param_4];
	ld.param.u32 	%r8, [compute_param_5];
	ld.param.v4.u32 	{%r14, %r15, %r16, %r17}, [compute_param_6];
	ld.param.f64 	%fd28, [compute_param_7+24];
	ld.param.f64 	%fd27, [compute_param_7+16];
	ld.param.f64 	%fd26, [compute_param_7+8];
	ld.param.f64 	%fd25, [compute_param_7];
	ld.param.f64 	%fd30, [compute_param_8+8];
	ld.param.f64 	%fd29, [compute_param_8];
	ld.param.u32 	%r13, [compute_param_9];
	ld.param.f64 	%fd31, [compute_param_10];
	mov.u32 	%r18, %ntid.x;
	mov.u32 	%r19, %ctaid.x;
	mov.u32 	%r20, %tid.x;
	mad.lo.s32 	%r21, %r18, %r19, %r20;
	setp.ge.u32	%p1, %r21, %r16;
	@%p1 bra 	BB0_17;

	mov.u32 	%r22, %ntid.y;
	mov.u32 	%r23, %ctaid.y;
	mov.u32 	%r24, %tid.y;
	mad.lo.s32 	%r25, %r22, %r23, %r24;
	setp.ge.u32	%p2, %r25, %r17;
	@%p2 bra 	BB0_17;

	cvt.rn.f64.u32	%fd34, %r21;
	fma.rn.f64 	%fd60, %fd27, %fd34, %fd25;
	cvt.rn.f64.u32	%fd35, %r25;
	fma.rn.f64 	%fd62, %fd28, %fd35, %fd26;
	setp.eq.s32	%p3, %r8, 3;
	selp.f64	%fd3, %fd29, %fd60, %p3;
	selp.f64	%fd4, %fd30, %fd62, %p3;
	mov.u32 	%r47, 0;
	mov.f64 	%fd64, 0d0000000000000000;
	mov.f64 	%fd63, 0d3FF0000000000000;
	setp.lt.s32	%p4, %r13, 1;
	@%p4 bra 	BB0_3;

	setp.eq.s32	%p5, %r8, 2;
	mov.u32 	%r47, 0;
	mov.f64 	%fd58, 0d3FF0000000000000;
	mov.f64 	%fd64, 0d0000000000000000;
	@%p5 bra 	BB0_10;
	bra.uni 	BB0_5;

BB0_10:
	mul.f64 	%fd15, %fd62, %fd62;
	mul.f64 	%fd16, %fd60, %fd60;
	add.f64 	%fd47, %fd16, %fd15;
	setp.ge.f64	%p11, %fd47, %fd31;
	@%p11 bra 	BB0_11;

	mul.f64 	%fd48, %fd60, %fd58;
	mul.f64 	%fd49, %fd62, %fd64;
	sub.f64 	%fd50, %fd48, %fd49;
	fma.rn.f64 	%fd63, %fd50, 0d4000000000000000, 0d3FF0000000000000;
	mul.f64 	%fd51, %fd60, %fd64;
	fma.rn.f64 	%fd52, %fd62, %fd58, %fd51;
	add.f64 	%fd64, %fd52, %fd52;
	sub.f64 	%fd53, %fd16, %fd15;
	add.f64 	%fd61, %fd3, %fd53;
	add.f64 	%fd54, %fd60, %fd60;
	fma.rn.f64 	%fd62, %fd54, %fd62, %fd4;
	setp.eq.f64	%p12, %fd61, 0d0000000000000000;
	setp.eq.f64	%p13, %fd62, 0d0000000000000000;
	and.pred  	%p14, %p12, %p13;
	add.s32 	%r47, %r47, 1;
	@%p14 bra 	BB0_13;

	setp.lt.s32	%p15, %r47, %r13;
	mov.f64 	%fd58, %fd63;
	mov.f64 	%fd60, %fd61;
	@%p15 bra 	BB0_10;
	bra.uni 	BB0_15;

BB0_5:
	mul.f64 	%fd7, %fd62, %fd62;
	mul.f64 	%fd8, %fd60, %fd60;
	add.f64 	%fd40, %fd8, %fd7;
	mov.f64 	%fd64, 0d0000000000000000;
	mov.f64 	%fd63, 0d3FF0000000000000;
	setp.ge.f64	%p6, %fd40, %fd31;
	@%p6 bra 	BB0_6;

	sub.f64 	%fd43, %fd8, %fd7;
	add.f64 	%fd61, %fd3, %fd43;
	add.f64 	%fd44, %fd60, %fd60;
	fma.rn.f64 	%fd62, %fd44, %fd62, %fd4;
	setp.eq.f64	%p7, %fd61, 0d0000000000000000;
	setp.eq.f64	%p8, %fd62, 0d0000000000000000;
	and.pred  	%p9, %p7, %p8;
	add.s32 	%r47, %r47, 1;
	@%p9 bra 	BB0_8;

	setp.lt.s32	%p10, %r47, %r13;
	mov.f64 	%fd60, %fd61;
	@%p10 bra 	BB0_5;
	bra.uni 	BB0_15;

BB0_3:
	mov.f64 	%fd61, %fd60;
	bra.uni 	BB0_15;

BB0_11:
	mov.f64 	%fd61, %fd60;
	mov.f64 	%fd63, %fd58;
	bra.uni 	BB0_15;

BB0_13:
	mov.u32 	%r47, %r13;
	bra.uni 	BB0_15;

BB0_6:
	mov.f64 	%fd61, %fd60;
	bra.uni 	BB0_15;

BB0_8:
	mov.u32 	%r47, %r13;

BB0_15:
	mad.lo.s32 	%r7, %r25, %r16, %r21;
	cvta.to.global.u64 	%rd6, %rd1;
	mul.wide.s32 	%rd7, %r7, 4;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.u32 	[%rd8], %r47;
	cvta.to.global.u64 	%rd9, %rd2;
	mul.wide.s32 	%rd10, %r7, 8;
	add.s64 	%rd11, %rd9, %rd10;
	st.global.f64 	[%rd11], %fd61;
	cvta.to.global.u64 	%rd12, %rd3;
	add.s64 	%rd13, %rd12, %rd10;
	st.global.f64 	[%rd13], %fd62;
	setp.ne.s32	%p16, %r8, 2;
	@%p16 bra 	BB0_17;

	cvta.to.global.u64 	%rd14, %rd4;
	add.s64 	%rd16, %rd14, %rd10;
	st.global.f64 	[%rd16], %fd63;
	cvta.to.global.u64 	%rd17, %rd5;
	add.s64 	%rd18, %rd17, %rd10;
	st.global.f64 	[%rd18], %fd64;

BB0_17:
	ret;
}


